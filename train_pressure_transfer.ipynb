{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575e5aa-5541-4cce-82c2-d2de0dfc2926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import sys\n",
    "import unet_uae_filter_16_32_32_64 as vae_util\n",
    "\n",
    "\n",
    "from layers import *\n",
    " \n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Flatten, Dense, Lambda, Reshape, concatenate, TimeDistributed, RepeatVector, ConvLSTM2D\n",
    "from convolutional_recurrent_3d import ConvLSTM3D\n",
    "from keras.models import Model\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf \n",
    "\n",
    "# tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
    "# tf.config.gpu.set_per_process_memory_growth(True)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.99\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc04da-7d5e-479f-92b7-95ab732fa4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, array_name_list):\n",
    "    hf_r = h5py.File(data_path, 'r')\n",
    "    result = []\n",
    "    for name in array_name_list:\n",
    "        result.append(np.array(hf_r.get(name)))\n",
    "    hf_r.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9279038-605f-4e23-8a07-3ce5e64b3c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data'\n",
    "# load training data\n",
    "data_path = os.path.join('/data/cees/sujiang/surrogate_3D/sim_0.1/40x40x20/channel_40x40x20_21tsteps_2924_satifying_cases_update.h5')\n",
    "p_t, logk = load_data(data_path, ['pressure', 'logk'])\n",
    "# sat_t = np.delete(sat_t, 1251, axis = 0) # index 1251 should be removed as an outlier\n",
    "# logk = np.delete(logk, 1251, axis = 0)\n",
    "# load eval data\n",
    "print('p_t shape is ', p_t.shape)\n",
    "print('logk shape is ', logk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da0358-17b8-42b0-82d8-a0699b29970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('p_t max is ', np.max(p_t))\n",
    "print('p_t min is ', np.min(p_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c801157e-f90c-4b8b-ade8-2483ca7e1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 10\n",
    "nr = logk.shape[0]\n",
    "train_nr = 100\n",
    "test_nr = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b1d55-4094-40e1-97db-4fb519d844f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_t_mean = np.mean(p_t[:train_nr, ...], axis = 0, keepdims = True)\n",
    "p_t = p_t - p_t_mean\n",
    "print('max p is ', np.max(p_t[:train_nr, ...]), ', min p is ', np.min(p_t[:train_nr, ...]))\n",
    "max_p = np.max(p_t[:train_nr, ...], axis=(0,1,2,3), keepdims = True)\n",
    "min_p = np.min(p_t[:train_nr, ...], axis=(0,1,2,3), keepdims = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d83a661-9b2c-4f63-93e9-fc3d3ff21184",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-6\n",
    "p_t = (p_t - min_p)/(max_p - min_p + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaac5a8-7b14-449c-a4aa-e5b7dbcdb686",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('max p is ', np.max(p_t), ', min p is ', np.min(p_t))\n",
    "print('max p train is ', np.max(p_t[:train_nr, ...]), ', min p train is ', np.min(p_t[:train_nr, ...]))\n",
    "print('max p validation is ', np.max(p_t[test_nr:, ...]), ', min p validation is ', np.min(p_t[test_nr:, ...]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e59ac-7554-46b5-a36f-dfa95d492d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_index = [1, 2, 3, 6, 8, 10, 12, 14, 17, 20]\n",
    "train_x = np.concatenate([logk[:train_nr, ...], p_t[:train_nr,:, :, :, [0]]], axis = -1)\n",
    "train_y = p_t[:train_nr, :, :, :, step_index]\n",
    "\n",
    "test_x = np.concatenate([logk[nr-test_nr:, ...],  p_t[nr-test_nr:, :, :, :, [0]]], axis = -1)\n",
    "test_y = p_t[nr-test_nr:,:, :, :, step_index]\n",
    "\n",
    "train_y = train_y.transpose(0, 4, 1, 2, 3)\n",
    "train_y = train_y[:, :, :, :, :, None]\n",
    "test_y = test_y.transpose(0, 4, 1, 2, 3)\n",
    "test_y = test_y[:, :, :, :, :, None]\n",
    "print('train_x shape is ', train_x.shape)\n",
    "print('train_y shape is ', train_y.shape)\n",
    "print('test_x shape is ', test_x.shape)\n",
    "print('test_y shape is ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3218f-ec36-46e4-ae97-95432d07fce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape=(20, 40, 40, 2)\n",
    "depth = 10\n",
    "input = Input(shape=input_shape, name='image')\n",
    "_, vae_model_base, _ = vae_util.create_vae(input_shape, depth)\n",
    "output_base = vae_model_base(input)\n",
    "# vae_model_base.summary(line_length=150)\n",
    "output_coarse = TimeDistributed(Conv3D(1, (3, 3, 3), strides = (2, 2, 2), padding='same', activation=None))(output_base)\n",
    "output = TimeDistributed(Conv3D(1, (3, 3, 3), padding='same', activation=None))(output_base)\n",
    "vae_model_fine = Model(input, output) \n",
    "vae_model_fine.summary(line_length=150)\n",
    "\n",
    "vae_model_coarse = Model(input, output_coarse) \n",
    "vae_model_coarse.summary(line_length=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee04f5-5be2-4a81-b120-3bb91de03e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'saved_models_2x2x2/'\n",
    "vae_model_coarse.load_weights(output_dir + 'coarse_saved-model-10steps-bs4-lr3e-4-pressure-detrend-hd-500-filter_16_32_32_64-mse-280-16.63.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd12b50-36a0-435b-bb6d-12ff9335c076",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_model_base.trainable = False\n",
    "vae_model_fine.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f354f20-0b39-495b-a7f4-ec91f73ee2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "train_nr = train_x.shape[0]\n",
    "test_nr = 20\n",
    "batch_size = 4\n",
    "num_batch = int(train_nr/batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b201468a-b85b-4b1f-9214-2e4a458acbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, t_decoded):\n",
    "    '''Total loss for the plain UAE'''\n",
    "    return K.mean(reconstruction_loss(x, t_decoded))\n",
    "\n",
    "\n",
    "def reconstruction_loss(x, t_decoded):\n",
    "    '''Reconstruction loss for the plain UAE'''\n",
    "\n",
    "    return K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2, axis=-1)\n",
    "\n",
    "def hard_data_loss(x, t_decoded):\n",
    "    '''Compute Hard Data at Well Loc'''\n",
    "    \n",
    "    well_loc_x = [14, 4, 37, 36, 9, 21]\n",
    "    well_loc_y = [31, 19, 3, 21, 4, 3]\n",
    "    result = 0.\n",
    "    for i in range(len(well_loc_x)):\n",
    "        result = result + K.sum((K.batch_flatten(x[:, :, :, well_loc_y[i], well_loc_x[i], :]) - K.batch_flatten(t_decoded[:, :, :, well_loc_y[i], well_loc_x[i], :]))**2, axis = -1)\n",
    "    return K.mean(result)\n",
    "\n",
    "def joint_loss(x, t_decoded):\n",
    "    return vae_loss(x, t_decoded) + 500 * hard_data_loss(x, t_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf7e0a-5577-4ed0-b332-b8b9c0709b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error(x, t_decoded):\n",
    "    return K.mean(K.abs(x - t_decoded) / (x + 0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc36b2-0f14-452a-a726-811424a6c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=3e-4)\n",
    "vae_model_fine.compile(loss = joint_loss, optimizer = opt, metrics = [vae_loss, hard_data_loss, relative_error])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d07a87-97d5-49c3-9432-fddfef0a2327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "lrScheduler = ReduceLROnPlateau(monitor = 'loss', factor = 0.5, patience = 10, cooldown = 1, verbose = 1, min_lr = 1e-7)\n",
    "filePath = 'saved_models_2x2x2/transfer_saved-model-10steps-bs4-lr3e-4-pressure-detrend-hd-500-filter_16_32_32_64-mse-{epoch:03d}-{val_loss:.2f}.h5'\n",
    "checkPoint = ModelCheckpoint(filePath, monitor = 'val_loss', verbose = 1, save_best_only = False, \\\n",
    "                             save_weights_only = True, mode = 'auto', period = 20)\n",
    "\n",
    "callbacks_list = [lrScheduler, checkPoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ab8e0-6ef1-463a-ad35-aa9aa1cb111c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = vae_model_fine.fit(train_x, train_y, batch_size = batch_size, epochs = epochs, \\\n",
    "                        verbose = 1, validation_data = (test_x, test_y), callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324c968-f168-4d3c-8a07-dd9ebe92423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('results/HISTORY-pressure-transfer-mse-hd500-filter_16_32_32_64.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'][10:300], label = 'loss')\n",
    "plt.plot(history.history['vae_loss'][10:300], label = 'vae_loss')\n",
    "plt.plot(history.history['val_loss'][10:300], '--', label = 'val_loss')\n",
    "plt.plot(history.history['val_vae_loss'][10:300], '--', label = 'val_vae_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a30e7-223e-4b0c-b469-0ce121ed76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf98447-8289-4442-b460-2c002a0b09d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
